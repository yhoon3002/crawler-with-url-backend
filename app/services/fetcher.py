"""
ì›¹í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸° (Archive.org í¬í•¨)
"""
import httpx    # HTTP ìš”ì²­ ë³´ë‚´ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ = ì›¹í˜ì´ì§€ ë‹¤ìš´ë¡œë“œìš©
from playwright.async_api import async_playwright   # ì‹¤ì œ ë¸Œë¼ìš°ì €ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì‘í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import asyncio  # ë¹„ë™ê¸° ì²˜ë¦¬
import random   # ëœë¤ ê°’ ìƒì„±(ë´‡ì²˜ëŸ¼ ì•ˆë³´ì´ê²Œ í•˜ë ¤ê³  ì‚¬ìš©)
from typing import Tuple


# ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ëŠ” User-Agent ëª©ë¡
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
]


def get_realistic_headers() -> dict:
    """
    ì§„ì§œ ë¸Œë¼ìš°ì €ê°€ ë³´ë‚´ëŠ” ê²ƒì²˜ëŸ¼ HTTP í—¤ë”ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜

    Returns:
        dict: HTTP ìš”ì²­ì— í¬í•¨í•  í—¤ë” ì •ë³´
    """
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
    }


async def fetch_html(url: str, timeout_s: float = 15.0, use_archive: bool = False) -> Tuple[str, bool]:
    """
    ì›¹í˜ì´ì§€ì˜ HTMLì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì¸ í•¨ìˆ˜
    ì°¨ë‹¨ë˜ë©´ ìë™ìœ¼ë¡œ Archive.orgì—ì„œ ê°€ì ¸ì˜´

    ë™ì‘ ìˆœì„œ:
    1. ì¼ë°˜ì ì¸ HTTP ìš”ì²­ìœ¼ë¡œ ì‹œë„í•¨
    2. ë§‰íˆë©´ Playwrightë¡œ ì‹¤ì œ ë¸Œë¼ìš°ì € ì‚¬ìš©í•¨
    3. ë§‰íˆë©´ Archive.orgì—ì„œ ê°€ì ¸ì˜¤ê¸°

    Args:
        url: ê°€ì ¸ì˜¬ ì›¹í˜ì´ì§€ ì£¼ì†Œ
        timeout_s: íƒ€ì„ì•„ì›ƒ ì‹œê°„(ì´ˆ)
        use_archive: Trueì‹œ ë°”ë¡œ ì•„ì¹´ì´ë¸Œ ì‚¬ìš©

    Returns:
        Tuple[str, bool]: (HTML ë¬¸ìì—´, ì•„ì¹´ì´ë¸Œ ì‚¬ìš©í–ˆëŠ”ì§€ ì—¬ë¶€)
    """

    # use_archiveê°€ Trueë©´ ë°”ë¡œ ì•„ì¹´ì´ë¸Œì—ì„œ ê°€ì ¸ì˜´
    if use_archive:
        print(f"Archive.orgì—ì„œ ê°€ì ¸ì˜´: {url}")
        html = await fetch_from_archive(url, timeout_s)
        return html, True

    # ì¼ë°˜ HTTP ìš”ì²­ìœ¼ë¡œ ì‹œë„í•¨
    try:
        # httpx.AsynClient: ë¹„ë™ê¸°ë¡œ HTTP ìš”ì²­ì„ ë³´ë‚´ëŠ” í´ë¼ì´ì–¸íŠ¸
        async with httpx.AsyncClient(
            timeout=timeout_s,  # timeout_sì´ˆ ì•ˆì— ì‘ë‹µ ì•ˆì˜¤ë©´ í¬ê¸°í•¨
            follow_redirects=True,  # ë¦¬ë‹¤ì´ë ‰ì…˜ ìë™ìœ¼ë¡œ ë”°ë¼ê°
            headers=get_realistic_headers()
        ) as client:
            resp = await client.get(url)    # GET ìš”ì²­ ë³´ëƒ„
            html = resp.text    # ì‘ë‹µì„ í…ìŠ¤íŠ¸(HTML)ë¡œ ë°›ìŒ

            # ì°¨ë‹¨ëëŠ”ì§€ í™•ì¸
            if is_blocked(html, resp.status_code):
                print(f"ì •ì  í¬ë¡¤ë§ ì°¨ë‹¨ë¨ -> ë¸Œë¼ìš°ì €ë¡œ ì¬ì‹œë„")
                html, blocked = await fetch_with_playwright(url, timeout_s)

                # ë¸Œë¼ìš°ì €ë„ ì•ˆë˜ë©´ ì•„ì¹´ì´ë¸Œ ì‹œë„
                if blocked:
                    print(f"ğŸš« ë¸Œë¼ìš°ì €ë„ ì°¨ë‹¨ë¨ -> Archive.org ì‹œë„")
                    html = await fetch_from_archive(url, timeout_s)
                    return html, True   # ì•„ì¹´ì´ë¸Œ ì‚¬ìš©

                return html, False  # ë¸Œë¼ìš°ì €ë¡œ ì„±ê³µ

            # HTMLì´ ì¶©ë¶„íˆ ê¸¸ë©´ ì„±ê³µ
            if len(html) > 1000:
                print(f"ì •ì  í¬ë¡¤ë§: {len(html)}ì")
                return html, False

    except Exception as e:
        print(f"ì •ì  í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # 2ë‹¨ê³„: Playwrightë¡œ ë¸Œë¼ìš°ì € ë Œë”ë§
    print(f"ğŸ­ Playwright ì‹¤í–‰: {url}")
    html, blocked = await fetch_with_playwright(url, timeout_s)

    # ë¸Œë¼ìš°ì €ë„ ì°¨ë‹¨ë˜ë©´ ì•„ì¹´ì´ë¸Œ ì‹œë„
    if blocked:
        print(f"ë¸Œë¼ìš°ì €ë„ ì°¨ë‹¨ë¨ -> Archive.org ì‹œë„")
        html = await fetch_from_archive(url, timeout_s)
        return html, True

    return html, False


def is_blocked(html: str, status_code: int) -> bool:
    """
    ì›¹ì‚¬ì´íŠ¸ê°€ ìš°ë¦¬ë¥¼ ì°¨ë‹¨í–‡ëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜

    ì°¨ë‹¨ íŒë‹¨ ê¸°ì¤€:
    1. HTTP ìƒíƒœ ì½”ë“œê°€ 403(Forbidden, ê¸ˆì§€ë¨)/429(Too Many Requests, ë„ˆë¬´ ë§ì€ ìš”ì²­)/503(service temporarily unavailable, ì„œë¹„ìŠ¤ ë¶ˆê°€)
    2. HTMLì´ ë„ˆë¬´ ì§§ìŒ (500ì ë¯¸ë§Œ)    ->  ì¶”í›„ ë³€ê²½í•´ì•¼ë¨
    3. "Access Denied", "Cloudflare", "captcha" ê°™ì€ ì°¨ë‹¨ ê´€ë ¨ ë‹¨ì–´ê°€ ìˆìŒ

    Args:
        html: ë°›ì€ HTML ë¬¸ìì—´
        status_code: HTTP ìƒíƒœ ì½”ë“œ

    Returns:
        bool: ì°¨ë‹¨ -> True / ì°¨ë‹¨ X -> False
    """
    if status_code in [403, 429, 503]:
        return True

    # HTML ê¸¸ì´ê°€ 500ì ë¯¸ë§Œì´ë©´ ì •ìƒì ì´ì§€ ì•Šë‹¤ê³  íŒë‹¨   ->  ì¶”í›„ ìˆ˜ì • í•„ìš”í• ë“¯ ?
    if len(html) < 500:
        return True

    # ì°¨ë‹¨ ê´€ë ¨ í‚¤ì›Œë“œ ëª©ë¡ë“¤
    block_keywords = [
        "Access Denied",
        "403 Forbidden",
        "Attention Required",
        "Cloudflare",
        "Security Check",
        "Please verify you are a human",
        "captcha",
        "blocked",
    ]

    html_lower = html.lower()
    for keyword in block_keywords:
        if keyword.lower() in html_lower:
            return True

    return False


async def fetch_with_playwright(url: str, timeout_s: float) -> Tuple[str, bool]:
    """
    Playwrightë¥¼ ì‚¬ìš©í•´ ì‹¤ì œ ë¸Œë¼ìš°ì €ë¡œ ì›¹í˜ì´ì§€ ì—´ê³  HTMLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

    ì¼ë°˜ HTTP ìš”ì²­ìœ¼ë¡œ ì•ˆë  ë•Œ ì‚¬ìš©í•¨
    ì‹¤ì œ Chrome ë¸Œë¼ìš°ì €ë¥¼ ìë™ìœ¼ë¡œ ì¼œì„œ ì‚¬ëŒì²˜ëŸ¼ ë³´ì´ê²Œ í•¨

    Args:
        url: ê°€ì ¸ì˜¬ ì›¹í˜ì´ì§€ ì£¼ì†Œ
        timeout_s: ìµœëŒ€ ê¸°ë‹¤ë¦´ ì‹œê°„

    Returns:
        Tuple[str, bool]: [HTML ë¬¸ìì—´, ì°¨ë‹¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€]
    """
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(
                headless=True,  # Trueë©´ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰í•¨
                args=[
                    '--disable-blink-features=AutomationControlled',    # ìë™í™”ë¼ëŠ” í‘œì‹œ ìˆ¨ê¸°ê¸°
                    '--disable-dev-shm-usage',  # ë©”ëª¨ë¦¬ ìµœì í™”
                    '--no-sandbox', # ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™”
                ]
            )

            # ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},   # í™”ë©´ í¬ê¸°
                user_agent=random.choice(USER_AGENTS),  # ëœë¤ User-Agent
                locale='ko-KR', # í•œêµ­ì–´ ì„¤ì •
                timezone_id='Asia/Seoul',   # ì„œìš¸ ì‹œê°„ëŒ€
            )

            # ìë™í™” íƒì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
            await context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
                window.chrome = { runtime: {} };
            """)

            page = await context.new_page()

            try:
                await page.goto(url, wait_until="domcontentloaded", timeout=int(timeout_s * 1000))

                # 1~2ì´ˆ ì •ë„ ëœë¤ ì‹œê°„ìœ¼ë¡œ ê¸°ë‹¤ë ¤ì„œ ì‚¬ëŒì²˜ëŸ¼ ì•ˆë³´ì´ê²Œ
                await asyncio.sleep(random.uniform(1.0, 2.0))

                html = await page.content()

                # ì°¨ë‹¨ëëŠ”ì§€ í™•ì¸
                blocked = is_blocked(html, 200)

                if not blocked:
                    print(f"Playwright: {len(html)}ì")

                return html, blocked

            finally:
                await context.close()
                await browser.close()

    except Exception as e:
        print(f"Playwright ì‹¤íŒ¨: {e}")
        return "", True


async def fetch_from_archive(url: str, timeout_s: float = 20.0) -> str:
    """
    Archive.orgì—ì„œ HTMLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    ì›ë³¸ ì‚¬ì´íŠ¸ ë§‰í ë•Œ ì‚¬ìš©

    Args:
        url: ì›ë³¸ ì›¹í˜ì´ì§€ ì£¼ì†Œ
        timeout_s: ìµœëŒ€ ê¸°ë‹¤ë¦´ ì‹œê°„

    Returns:
        str: ì•„ì¹´ì´ë¸Œëœ HTML

    Raises:
        Exception: ì•„ì¹´ì´ë¸Œì— í•´ë‹¹ URLì´ ì—†ê±°ë‚˜ ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ
    """
    try:
        async with httpx.AsyncClient(timeout=timeout_s, follow_redirects=True) as client:
            # ì•„ì¹´ì´ë¸Œì— URLì´ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•¨
            availability_url = f"https://archive.org/wayback/available?url={url}"
            resp = await client.get(availability_url)
            data = resp.json()

            # ì•„ì¹´ì´ë¸Œê°€ ìˆëŠ”ì§€ í™•ì¸
            if not data.get("archived_snapshots"):
                raise Exception("ì•„ì¹´ì´ë¸Œì— í•´ë‹¹ URLì´ ì—†ìŒ!!!")

            # ê°€ì¥ ìµœê·¼ ì €ì¥ëœ ë²„ì „ ì°¾ì•„ì˜´
            closest = data["archived_snapshots"].get("closest")
            if not closest or not closest.get("available"):
                raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ ì•„ì¹´ì´ë¸Œê°€ ì—†ìŒ!!!")

            # ì•„ì¹´ì´ë¸Œ URLê³¼ ì €ì¥ ì‹œì 
            archive_url = closest["url"]
            timestamp = closest.get("timestamp", "ì•Œ ìˆ˜ ì—†ìŒ")

            print(f"Archive.orgì—ì„œ ì°¾ìŒ: {timestamp} ë²„ì „")

            # ì•„ì¹´ì´ë¸Œëœ í˜ì´ì§€ ê°€ì ¸ì˜´
            # id_ í”Œë˜ê·¸ ì¶”ê°€í•˜ë©´ ì•„ì¹´ì´ë¸Œì˜ UI ì—†ì´ ì›ë³¸ ì»¨í…ì¸ ë§Œ ë°›ì„ ìˆ˜ ìˆìŒ
            if "web.archive.org/web/" in archive_url:
                # URL ì¬êµ¬ì„± ë° id_ í”Œë˜ê·¸ ì¶”ê°€
                parts = archive_url.split("/web/")
                if len(parts) == 2:
                    archive_url = f"{parts[0]}/web/{parts[1].split('/')[0]}id_/{'/'.join(parts[1].split('/')[1:])}"

            # ì•„ì¹´ì´ë¸Œ í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ
            resp = await client.get(archive_url, headers=get_realistic_headers())
            html = resp.text

            print(f"Archive.org: {len(html)}ì (ì•„ì¹´ì´ë¸Œ ë²„ì „)")
            return html

    except Exception as e:
        print(f"Archive.org ì‹¤íŒ¨: {e}")
        raise Exception(f"ì›ë³¸ ì‚¬ì´íŠ¸ ë° ì•„ì¹´ì´ë¸Œ ëª¨ë‘ ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}")